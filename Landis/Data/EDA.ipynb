{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "###list of data files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import math\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import more_itertools as mit\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import *\n",
    "### Dynamic Time Warping(DTW) method\n",
    "def DTWDistance(s1, s2):\n",
    "    alignment = dtw(s1,s2, keep_internals=True)\n",
    "    d = alignment.normalizedDistance\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_list_of_pd(clusters_list):\n",
    "    clusters_data_list = []\n",
    "    for i in clusters_list:\n",
    "        temp_data = pd.DataFrame(i, columns =['SecurityID', 'Sector', 'Industry','Sub_Industry','Seniority','Issuedby','Country','Rating','AmountIssued','Coupon','IssueDate','MaturityDate','ModifiedDuration'])\n",
    "        clusters_data_list.append(temp_data)\n",
    "    return clusters_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_rating(x):\n",
    "    x = float(x)\n",
    "    if x < 0:\n",
    "        return 'NR'\n",
    "    elif x >0 and x<=0.5:\n",
    "        return 'D'\n",
    "    elif x > 0.5 and x<=1.5:\n",
    "        return 'C'\n",
    "    elif x > 1.5 and x<=2.5:\n",
    "        return 'CC-'\n",
    "    elif x > 2.5 and x<=3.5:\n",
    "        return 'CC'\n",
    "    elif x >3.5 and x<=4.5:\n",
    "        return 'CC+'\n",
    "    elif x >4.5 and x <=5.5:\n",
    "        return 'CCC-'\n",
    "    elif x >5.5 and x <=6.5:\n",
    "        return 'CCC'\n",
    "    elif x >6.5 and x<=7.5:\n",
    "        return 'CCC+'\n",
    "    elif x >7.5 and x <= 8.5:\n",
    "        return 'B-'\n",
    "    elif x>8.5 and x <=9.5:\n",
    "        return 'B'\n",
    "    elif x> 9.5 and x <= 10.5:\n",
    "        return 'B+'\n",
    "    elif x >10.5 and x<=11.5:\n",
    "        return 'BB-'\n",
    "    elif x > 11.5 and x<=12.5:\n",
    "        return 'BB'\n",
    "    elif x >12.5 and x<=13.5:\n",
    "        return 'BB+'\n",
    "    elif x>13.5 and x <=14.5:\n",
    "        return 'BBB-'\n",
    "    elif x>14.5 and x<=15.5:\n",
    "        return 'BBB'\n",
    "    elif x>15.5 and x<=16.5:\n",
    "        return 'BBB+'\n",
    "    elif x>16.5 and x<=17.5:\n",
    "        return 'A-'\n",
    "    elif x > 17.5 and x<=18.5:\n",
    "        return 'A'\n",
    "    elif x >18.5 and x<=19.5:\n",
    "        return 'A+'\n",
    "    elif x>19.5 and x<=20.5:\n",
    "        return 'AA-'\n",
    "    elif x >20.5 and x<=21.5:\n",
    "        return 'AA'\n",
    "    elif x>21.5 and x<=22.5:\n",
    "        return 'AA+'\n",
    "    else:\n",
    "        return 'AAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rating_data(data):\n",
    "    #data = data[data['KeyDate']<=end_date]\n",
    "    rating = data.groupby('SecurityID',as_index=False).mean()\n",
    "    rating['RatingSP'] = rating['RatingSP'].apply(lambda x:assign_rating(x))\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_clusters(clusters,bond_spread_list,security_data,rating_data):\n",
    "    temp_list = []\n",
    "    for cluster in clusters:\n",
    "        temp_list2 = []\n",
    "        for bond_index in cluster:\n",
    "            bond_id = bond_spread_list[bond_index][1]\n",
    "            bond_Sector = security_data[security_data['SecurityID']==bond_id].SecuritySector.iloc[0]\n",
    "            bond_Industry = security_data[security_data['SecurityID'] == bond_id].SecurityIndustry.iloc[0]\n",
    "            bond_sub_Industry = security_data[security_data['SecurityID'] == bond_id].SecuritySubIndustry.iloc[0]\n",
    "            bond_Seniority = security_data[security_data['SecurityID'] == bond_id].Seniority.iloc[0]\n",
    "            bond_Issuer =security_data[security_data['SecurityID'] == bond_id].Issuer.iloc[0]\n",
    "            bond_countryrisk =security_data[security_data['SecurityID'] == bond_id].CountryRisk.iloc[0]\n",
    "            bond_amountIssued =security_data[security_data['SecurityID'] == bond_id].AmountIssued.iloc[0]\n",
    "            bond_coupon =security_data[security_data['SecurityID'] == bond_id].Coupon.iloc[0]\n",
    "            bond_MaturityDate =security_data[security_data['SecurityID'] == bond_id].MaturityDate.iloc[0]\n",
    "            bond_issuedate =security_data[security_data['SecurityID'] == bond_id].IssueDate.iloc[0]\n",
    "            bond_duration =security_data[security_data['SecurityID'] == bond_id].ModifiedDuration.iloc[0]\n",
    "            try:\n",
    "                bond_rating=rating_data[rating_data['SecurityID'] == bond_id].RatingSP.iloc[0]\n",
    "            except:\n",
    "                bond_rating = 'Not Founded'\n",
    "            temp_tuple = (bond_id,bond_Sector,bond_Industry,bond_sub_Industry,bond_Seniority,bond_Issuer,bond_countryrisk,bond_rating,bond_amountIssued,bond_coupon,bond_issuedate,bond_MaturityDate,bond_duration)\n",
    "            temp_list2.append(temp_tuple)\n",
    "        temp_list.append(temp_list2)\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_left_right(data1,data2):\n",
    "    temp_data = data1.append(data2)\n",
    "    return temp_data\n",
    "\n",
    "def merg_sort(list_data):\n",
    "    list_length = len(list_data)\n",
    "    if list_length == 1:\n",
    "        output = list_data[0][2]\n",
    "        return output\n",
    "    else:\n",
    "        mid_point = math.floor(list_length/2)\n",
    "        #print(len(list_data[:mid_point]))\n",
    "        left = list_data[mid_point:]\n",
    "        right = list_data[:mid_point]\n",
    "        return merge_left_right(merg_sort(left), merg_sort(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data,period_of_time,start_date):\n",
    "    #transfer start_date to datetime()\n",
    "    time_list = start_date.split('-')\n",
    "    year = int(time_list[0])\n",
    "    month = int(time_list[1])\n",
    "    date = int(time_list[2])\n",
    "    start_datetime = datetime.datetime(year, month, date)\n",
    "    data['KeyDate'] = pd.to_datetime(data['KeyDate'])\n",
    "    data['MaturityDate'] = pd.to_datetime(data['MaturityDate'])\n",
    "    data['IssueDate'] = pd.to_datetime(data['IssueDate'])\n",
    "    ###find the end date:\n",
    "    end_datetime = start_datetime + datetime.timedelta(days=period_of_time)\n",
    "    end_date = str(end_datetime.date())\n",
    "    #####select data before the end_date\n",
    "    data = data[data['KeyDate'] >= start_datetime]\n",
    "    data = data[data['KeyDate'] <= end_date]\n",
    "    data = data[data['IssueDate'] <= start_datetime]\n",
    "    data = data[data['MaturityDate'] >= end_date]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fill(data_list,index):\n",
    "    for i in data_list:\n",
    "        try:\n",
    "            fill_the_GSpeard(i)\n",
    "        except:\n",
    "            index.append(i)\n",
    "    return index,data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(lists,initial_data):\n",
    "    data = initial_data\n",
    "    for file in lists:\n",
    "        path = 'C:\\\\Users\\\\y437l\\\\OneDrive\\\\MMAI\\\\Capstone\\\\Data\\\\{}'.format(file)\n",
    "        temp_data = pd.read_csv(path)\n",
    "        print(len(temp_data))\n",
    "        data = data.append(temp_data)\n",
    "        print(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "security_data = pd.read_csv(\"C:/Users/y437l/OneDrive/MMAI/Capstone/Data/SecurityData - Copy-LAPTOP-OAEJRPE8.csv\")\n",
    "security_data =security_data[['SecurityID','Currency','IssueDate','MaturityDate']]\n",
    "### merge spread data togther\n",
    "sc = MinMaxScaler()\n",
    "data = pd.read_csv(\"C:/Users/y437l/OneDrive/MMAI/Capstone/Data/1.csv\")\n",
    "file_lists = ['14426.csv','24001.csv','36128.csv','48087.csv','55086.csv']\n",
    "final_data = merge_data(file_lists,data)\n",
    "#final_data = data\n",
    "###left join the currency data into the spread data\n",
    "final_data = final_data.merge(security_data, on=['SecurityID'], how='left')\n",
    "final_data.dropna(subset=[\"ZSpread\"],inplace=True)\n",
    "###select currency as USD\n",
    "final_data_1 = final_data[final_data.Currency == 'USD']\n",
    "final_data = final_data_1.groupby('SecurityID')\n",
    "###create a list of bond with data\n",
    "bonds_list = [final_data.get_group(x) for x in final_data.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_the_GSpeard(data):\n",
    "    ##calucate the spread between gspread and z spread if the gspread is not 0.\n",
    "    data['Spread_G_Z'] = data.GSpread - data.ZSpread\n",
    "    ###find the nan data's index in the data:\n",
    "    index_with_indicator = data.GSpread.isna()\n",
    "    index_with_indicator = index_with_indicator.tolist()\n",
    "    index_list = []\n",
    "    for indx in range(0,len(index_with_indicator)):\n",
    "        if index_with_indicator[indx] == True:\n",
    "            index_list.append(indx)\n",
    "    #print(index_list)\n",
    "    ##find concustive missing value:\n",
    "    ##example:[(22, 39), 303, (326, 343), 607]\n",
    "    star_end_dates = find_ranges(index_list)\n",
    "    missing_date_dict={}\n",
    "    for periods in star_end_dates:\n",
    "        if type(periods) !=tuple:\n",
    "            missing_date_dict[str(periods)] = spread_slope(data,periods)\n",
    "            value = data.Spread_G_Z.iloc[periods-1]+missing_date_dict[str(periods)][3]\n",
    "            print(value)\n",
    "            data.GSpread.iloc[periods] = data.ZSpread.iloc[periods]+value\n",
    "            print(data.GSpread.iloc[periods])\n",
    "        else:\n",
    "            missing_date_dict['{}-{}'.format(periods[0],periods[1])] = spread_slope(data, periods)\n",
    "            star = missing_date_dict['{}-{}'.format(periods[0],periods[1])][0]\n",
    "            end = missing_date_dict['{}-{}'.format(periods[0],periods[1])][1]\n",
    "            slope = missing_date_dict['{}-{}'.format(periods[0],periods[1])][3]\n",
    "            for days in range(star+1,end):\n",
    "                value = data.Spread_G_Z.iloc[star] + (days-star)*slope\n",
    "                data.GSpread.iloc[days] = data.ZSpread.iloc[days]+value\n",
    "    print(missing_date_dict)\n",
    "    #if missing_date_dict['{}-{}'.format(periods[0],periods[1])][3] >=1:\n",
    "        #print(missing_date_dict)\n",
    "        #print(\"Warning {}\".format(data.SecurityID.iloc[0]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ranges(iterable):\n",
    "    \"\"\"Yield range of consecutive numbers.\"\"\"\n",
    "    for group in mit.consecutive_groups(iterable):\n",
    "        group = list(group)\n",
    "        if len(group) == 1:\n",
    "            yield group[0]\n",
    "        else:\n",
    "            yield group[0], group[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_slope(data,input):\n",
    "    if type(input) != tuple:\n",
    "        star = input-1\n",
    "        end = input+1\n",
    "    else:\n",
    "        star = input[0] - 1\n",
    "        end = input[1] + 1\n",
    "    if end == len(data):\n",
    "        slope = data.Spread_G_Z.iloc[star]\n",
    "        end = 'None'\n",
    "        gap = 1\n",
    "    else:\n",
    "        print(input)\n",
    "        star_point = data.Spread_G_Z.iloc[star]\n",
    "        print(star_point)\n",
    "        end_point = data.Spread_G_Z.iloc[end]\n",
    "        print(end_point)\n",
    "        gap = (end-star)\n",
    "        print(gap)\n",
    "        slope = (end_point - star_point) / gap\n",
    "        print(slope)\n",
    "    return (star, end, gap,slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data,period_of_time,start_date):\n",
    "    #transfer start_date to datetime()\n",
    "    time_list = start_date.split('-')\n",
    "    year = int(time_list[0])\n",
    "    month = int(time_list[1])\n",
    "    date = int(time_list[2])\n",
    "    start_datetime = datetime.datetime(year, month, date)\n",
    "    data['KeyDate'] = pd.to_datetime(data['KeyDate'])\n",
    "    data['MaturityDate'] = pd.to_datetime(data['MaturityDate'])\n",
    "    data['IssueDate'] = pd.to_datetime(data['IssueDate'])\n",
    "    ###find the end date:\n",
    "    end_datetime = start_datetime + datetime.timedelta(days=period_of_time)\n",
    "    end_date = str(end_datetime.date())\n",
    "    #####select data before the end_date\n",
    "    data = data[data['KeyDate'] <= end_date]\n",
    "    data = data[data['IssueDate'] <= start_datetime]\n",
    "    data = data[data['MaturityDate'] >= end_date]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(num,listoftuble):\n",
    "    temp_list = []\n",
    "    for i in listoftuble:\n",
    "        if i[0] == num:\n",
    "            temp_list.append(i)\n",
    "    return temp_list\n",
    "\n",
    "## Select the data with only spread percentage change.\n",
    "def select_spread_data(listoftuble):\n",
    "    temp_list = []\n",
    "    for i in listoftuble:\n",
    "        temp_list.append(i[2])\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemtic_data_index =[]\n",
    "problem_data_index,bonds_list = apply_fill(bonds_list,problemtic_data_index)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time),'Next Step:Percentage Changed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bonds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_spread_list = []\n",
    "for bond in bonds_list:\n",
    "    try:\n",
    "        bond['avg_GSpread'] = bond['GSpread'].rolling(window=10).mean()\n",
    "        bond.dropna(subset=['avg_GSpread'],inplace=True)\n",
    "        bond = sliding_windows(bond, 90, '2019-01-15')\n",
    "        if \"-\" not in bond.G_change.values:\n",
    "            bond_spread_list.append((len(bond.GSpread.values),bond.SecurityID.iloc[0],bond))\n",
    "        else:\n",
    "            print(bond.SecurityID.iloc[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bond_spread_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = merg_sort(bond_spread_list)\n",
    "new_data = new_data[new_data[\"avg_GSpread\"]!=\"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data['G_scale'] = sc.fit_transform(new_data[['avg_GSpread']], y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_2 = new_data.groupby('SecurityID')\n",
    "bonds_list_2 = [final_data_2.get_group(x) for x in final_data_2.groups]\n",
    "bond_dict = {}\n",
    "bond_spread_change_scaled_list = []\n",
    "for bond in bonds_list_2:\n",
    "    bond_spread_change_scaled_list.append((len(bond.G_change.values), bond.SecurityID.iloc[0], bond.G_scale.values))\n",
    "    bond_dict[bond.SecurityID.iloc[0]] = bond.ModifiedDuration_Plain.iloc[-1]\n",
    "   #bond_spread_change_scaled_list.append((len(bond.G_change.values), bond.SecurityID.iloc[0], bond.GSpread.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_maturity = pd.DataFrame(bond_dict.items(),columns = ['SecurityID','ModifiedDuration'])\n",
    "bond_maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_spread_change_scaled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_1 = select_data(33, bond_spread_change_scaled_list)\n",
    "test_cluster_1_with_spread = select_spread_data(test_cluster_1)\n",
    "print(len(test_cluster_1_with_spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_cluster_1\n",
    "for c in test_cluster_1:\n",
    "    plt.plot(c[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##perform randon walk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_shape = (2, 2)\n",
    "from minisom import MiniSom    \n",
    "som = MiniSom(som_shape[0], som_shape[1], 33, sigma=1.7, learning_rate=.6, activation_distance='euclidean',\n",
    "            neighborhood_function='gaussian', random_seed=10)\n",
    "som.pca_weights_init(test_cluster_1_with_spread)\n",
    "som.train_batch(test_cluster_1_with_spread, 1500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each neuron represents a cluster\n",
    "winner_coordinates = np.array([som.winner(x) for x in test_cluster_1_with_spread]).T\n",
    "# with np.ravel_multi_index we convert the bidimensional\n",
    "# coordinates to a monodimensional index\n",
    "cluster_index = np.ravel_multi_index(winner_coordinates, som_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get the cluster\n",
    "def create_cluster_list(cluster_index):\n",
    "    temp_1 = []\n",
    "    for i in np.unique(cluster_index):\n",
    "        temp_2 = []\n",
    "        for n in range(0,len(cluster_index)):\n",
    "            if cluster_index[n] == i:\n",
    "                temp_2.append(n)\n",
    "        temp_1.append(temp_2)\n",
    "    return temp_1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = create_cluster_list(cluster_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfertime(x):\n",
    "    try:\n",
    "        l = x.split(' ')\n",
    "        g = l[0].split('-')\n",
    "        f = datetime.datetime(int(g[0]),int(g[1]),int(g[2]))\n",
    "        return f\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_duration(x,y):\n",
    "    try:\n",
    "        final = y-x\n",
    "        return final\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_data = pd.read_csv(\"C:/Users/y437l/OneDrive/MMAI/Capstone/Data/SecurityData - Copy-LAPTOP-OAEJRPE8.csv\")\n",
    "rating_data = process_rating_data(pd.read_csv(\"C:/Users/y437l/OneDrive/MMAI/Capstone/Data/Rating.csv\"))\n",
    "security_data = security_data.merge(bond_maturity,on=['SecurityID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_list = grab_clusters(clusters,bond_spread_list,security_data,rating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list = transfer_to_list_of_pd(clusters_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_data_list[0].to_csv('test0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_cluster_1\n",
    "for c in clusters_data_list[3]['SecurityID']:\n",
    "    plt.plot(new_data[new_data['SecurityID']==c].G_scale.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_cluster_1\n",
    "for c in clusters_data_list[1]['SecurityID']:\n",
    "    plt.plot(new_data[new_data['SecurityID']==c].G_scale.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_cluster_1\n",
    "for c in clusters_data_list[0]['SecurityID']:\n",
    "    plt.plot(new_data[new_data['SecurityID']==c].G_scale.values)\n",
    "plt.show()\n",
    "print(len(clusters_data_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "prof = ProfileReport(clusters_data_list[0])\n",
    "prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prof1 = ProfileReport(clusters_data_list[1])\n",
    "prof1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof3 = ProfileReport(clusters_data_list[3])\n",
    "prof3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof2 = ProfileReport(clusters_data_list[2])\n",
    "prof2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
